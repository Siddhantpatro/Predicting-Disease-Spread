# -*- coding: utf-8 -*-
"""Dengue_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EtRytCD5jhMqTehpZSbb363EcYI0P_pC
"""

# Basic Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# For Splitting, Standardizing and encoding
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Random forest regressor for Regression
from sklearn.ensemble import RandomForestRegressor

# Xgboost regressor for regression
from xgboost import XGBRegressor

# For accuracy score
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score

# For warning
import warnings
warnings.filterwarnings("ignore")

from google.colab import files
uploaded = files.upload()



"""**Importing all the three datasets.**"""

import io
df_train_features = pd.read_csv(io.BytesIO(uploaded['dengue_features_train.csv']))
df_train_labels = pd.read_csv(io.BytesIO(uploaded['dengue_labels_train.csv']))
df_test = pd.read_csv(io.BytesIO(uploaded['dengue_features_test.csv']))

print(df_train_features.shape)
df_train_features.head()

print(df_train_labels.shape)
df_train_labels.head()

print(df_test.shape)
df_test.head()



"""**Data preprocessing for Train dataset.**"""

le = LabelEncoder()

df_train_features['week_start_date'] = df_train_features['week_start_date'].astype('datetime64').astype(int).astype(float)

df_train_features['city'] = le.fit_transform(df_train_features['city'])
df_train_features['week_start_date'] = le.fit_transform(df_train_features['week_start_date'])

column = []
cols_dtype = [i for i in df_train_features.dtypes]
for i,j in zip(df_train_features.columns, cols_dtype):
  if j!='object':
    column.append(i)
df_train_features[column] = df_train_features[column].fillna(df_train_features.mean())



"""**Final Train dataset.**"""

New_df = df_train_features[column]
New_df.head()

New_df_le = New_df.apply(LabelEncoder().fit_transform)
New_df_le.head()



"""**Data preprocessing for test dataset**"""

df_test['week_start_date'] = df_test['week_start_date'].astype('datetime64').astype(int).astype(float)

df_test['city'] = le.fit_transform(df_test['city'])
df_test['week_start_date'] = le.fit_transform(df_test['week_start_date'])

column = []
cols_dtype = [i for i in df_test.dtypes]
for i,j in zip(df_test.columns, cols_dtype):
  if j!='object':
    column.append(i)
df_test[column] = df_test[column].fillna(df_test.mean())

New_df_test = df_test[column]
New_df_test.head(10)



"""**Final Test dataset.**"""

New_df_test_le = New_df_test.apply(LabelEncoder().fit_transform)



"""**Outliers Present in the dataset.**"""

# Z_Score method for detection of outlier in the train dataset

z = np.abs(stats.zscore(df_train_features[column]))

threshold = 3
rows_cols = np.where(z > 3)

df_zscore = pd.DataFrame(rows_cols, index = ['Rows', 'Columns'])

# Anomaly dataframe contains the outlier detected using z score

anomaly=df_train_features[column].iloc[rows_cols]
df_anomaly = pd.DataFrame(anomaly)

# Function to print rows and columns values which contains the outlier

final_df = df_zscore.transpose()

rows = list(final_df['Rows'])
cols = list(final_df['Columns'])

# Details about both rows and columns containing outliers
final = []
for i in range(len(cols)):
  val = df_train_features[column[cols[i]]][rows[i]]
  final.append(val)
  
df_highlight = pd.DataFrame(final, columns = ['outliers'])

# Pandas style.apply method is used to highlight the outlier values in the dataset. Here the outliers are red coloured 

def highlight_column(s):
  global vals
  l = []
  for i in s:
    if i in final:
      l.append(True)
    else:
      l.append(False)
  vals = pd.Series(l)
  return ['color: red' if v else '' for v in vals]

df_train_features[column].style.apply(highlight_column, axis = 0)



"""**y containing the label column and 
X containing the features column.**
"""

y = df_train_labels['total_cases']

X = New_df_le

X.head(10)



"""**Splitting of the dataset using train_test_split method.**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.35, random_state = 42)

X_train.shape ,y_train.shape



"""**Standard Scaler for scaling of the data for training purpose.**"""

scaler = StandardScaler()

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)



"""**XGBOOST REGRESSOR**"""

xgbr = XGBRegressor(verbosity=0)

xgbr.fit(X_train, y_train)

"""*Prediction accuracy.*"""

xgbr_score = xgbr.score(X_train, y_train)
xgbr_score



"""**Prediction on X_test dataset using Xgb regressor.**"""

y_pred_xgb = xgbr.predict(X_test)



"""**RANDOM FOREST REGRESSOR**"""

from sklearn.ensemble import RandomForestRegressor
rfr = RandomForestRegressor()

rfr.fit(X_train, y_train)

"""*Random forest regression score.*"""

rfr_score = rfr.score(X_test, y_test)
rfr_score



"""**Prediction on X_test using random forest regressor.**"""

y_predicted = rfr.predict(X_test)
y_predicted = np.array(y_predicted)



"""**Dataframe containing arranged in descending order of model's score.**"""

models = pd.DataFrame({   
    'Model': ['XGBoost Regressor', 'Random Forest Regressor'],
    'Score': [xgbr_score, rfr_score]})
models.sort_values(by='Score', ascending=False)

"""*Since XGBoost gives around 93.6 % accuracy. So this algorithm is more suited for prediction.*"""



"""**Distribution plot for y_pred_xgb.**"""

sns.displot(y_pred_xgb)
plt.xlabel('y_pred_xgb')
plt.title('Graph for y_pred_xgb')



"""**Distribution plot for y_predicted.**"""

sns.displot(y_predicted)
plt.xlabel('y_predicted')
plt.title('Graph for y_predicted')



"""**True value vs Predicted value**"""

plt.scatter(y_test, y_pred_xgb)

plt.xlabel('y_pred_xgb')
plt.ylabel('y_test')

plt.title('True value vs predicted value')

plt.grid(True)

plt.style.use('fivethirtyeight')

"""**R2, Mean Absolute score and Mean Squared score.**"""

print('R2 score : ', round(r2_score(y_test, y_pred_xgb)*100, 2))
print('MAE score : ', mean_absolute_error(y_test, y_pred_xgb))
print('MSE score : ', mean_squared_error(y_test, y_pred_xgb))



"""**"total_cases" was predicted from test dataset using Xgboost algorithm.**"""

New_df_test_le['total_cases'] = xgbr.predict(New_df_test_le.values)
New_df_test_le['total_cases']



"""**Conversion from float64 to int64 for submission purpose.**"""

New_df_test_le['total_cases'] = New_df_test_le['total_cases'].astype('int64')

New_df_test_le['total_cases']



"""# Submission File in CSV format."""

New_df_test = pd.concat([New_df_test, New_df_test_le[['total_cases']]], axis = 1)

New_df_test.head(10)

New_df_test = New_df_test.replace({0:'iq',1:'sj'})

New_df_test[['city','year','weekofyear','total_cases']].to_csv('Xgbr_submit.csv', index = False)

